{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734589f8",
   "metadata": {},
   "source": [
    "# Silver Price Prediction - ML Lab Project\n",
    "\n",
    "## 1. Dataset Information\n",
    "- **Source**: Yahoo Finance (Silver Futures SI=F)\n",
    "- **Period**: 2016-2026 (10 years daily data)\n",
    "- **Target**: Next day's closing price (Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30364d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "import joblib, os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3173b59",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('silver_prices_10years.csv')\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b981c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values:\", df.isnull().sum().sum())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154c4c1",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc89958e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m,\u001b[32m4\u001b[39m))\n\u001b[32m      3\u001b[39m plt.plot(df[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m], df[\u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df['Date'], df['Close'])\n",
    "plt.title('Silver Prices Over Time')\n",
    "plt.xlabel('Date'); plt.ylabel('Price (USD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f26fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df[['Open','High','Low','Close','Volume']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b56cc",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e94dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    for lag in [1,2,3,5,7]: df[f'Close_Lag_{lag}'] = df['Close'].shift(lag)\n",
    "    for w in [5,10,20]: df[f'MA_{w}'] = df['Close'].rolling(w).mean()\n",
    "    df['Momentum'] = df['Close'].pct_change(5)\n",
    "    df['Volatility'] = df['Close'].rolling(5).std()\n",
    "    df['Target'] = df['Close'].shift(-1)\n",
    "    return df.dropna()\n",
    "\n",
    "df_feat = create_features(df)\n",
    "print(f\"Features created. Shape: {df_feat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9c526",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4441fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df_feat.columns if c not in ['Date','Target','Close']]\n",
    "X, y = df_feat[features], df_feat['Target']\n",
    "train_size = int(len(X)*0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b17ea2",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f85932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    return {'MAE':mean_absolute_error(y_true,y_pred), \n",
    "            'RMSE':np.sqrt(mean_squared_error(y_true,y_pred)),\n",
    "            'R2':r2_score(y_true,y_pred)}\n",
    "\n",
    "models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.01),\n",
    "    'DecisionTree': DecisionTreeRegressor(max_depth=10),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100,max_depth=15),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'SVR': SVR(kernel='rbf', C=100)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_s, y_train)\n",
    "    pred = model.predict(X_test_s)\n",
    "    metrics = evaluate(y_test, pred)\n",
    "    results.append({'Model':name, **metrics})\n",
    "    print(f\"{name}: R2={metrics['R2']:.4f}, RMSE={metrics['RMSE']:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('R2', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c247e4c",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28491f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "ax[0].barh(results_df['Model'], results_df['R2'], color='steelblue')\n",
    "ax[0].set_xlabel('R� Score'); ax[0].set_title('R� (Higher=Better)')\n",
    "ax[1].barh(results_df['Model'], results_df['RMSE'], color='coral')\n",
    "ax[1].set_xlabel('RMSE'); ax[1].set_title('RMSE (Lower=Better)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660684c",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(RandomForestRegressor(),\n",
    "    {'n_estimators':[50,100,150],'max_depth':[10,15,20]}, cv=3, scoring='r2')\n",
    "rf_grid.fit(X_train_s, y_train)\n",
    "print(f\"Best params: {rf_grid.best_params_}\")\n",
    "rf_pred = rf_grid.predict(X_test_s)\n",
    "rf_metrics = evaluate(y_test, rf_pred)\n",
    "print(f\"Tuned RF: R2={rf_metrics['R2']:.4f}, RMSE={rf_metrics['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b0772",
   "metadata": {},
   "source": [
    "## 9. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1587c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'Feature':features,'Importance':rf_grid.best_estimator_.feature_importances_})\n",
    "importance = importance.sort_values('Importance',ascending=False).head(10)\n",
    "plt.barh(importance['Feature'], importance['Importance'])\n",
    "plt.xlabel('Importance'); plt.title('Top 10 Features')\n",
    "plt.gca().invert_yaxis(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912382e",
   "metadata": {},
   "source": [
    "## 10. Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09efe50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_test.values[:100], label='Actual')\n",
    "plt.plot(rf_pred[:100], label='Predicted', alpha=0.7)\n",
    "plt.legend(); plt.title('Actual vs Predicted'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793da8ac",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "joblib.dump(rf_grid.best_estimator_, 'saved_models/best_model.pkl')\n",
    "results_df.to_csv('results.csv', index=False)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc6841",
   "metadata": {},
   "source": [
    "## 12. Model Explanations\n",
    "\n",
    "| Model | How it Works | Pros | Cons |\n",
    "|-------|-------------|------|------|\n",
    "| Linear | Fits line minimizing squared errors | Fast, interpretable | Linear assumption |\n",
    "| Ridge | Linear + L2 penalty | Handles multicollinearity | No feature selection |\n",
    "| Lasso | Linear + L1 penalty | Feature selection | May drop important features |\n",
    "| Decision Tree | Recursive splits | Non-linear, interpretable | Overfits easily |\n",
    "| Random Forest | Ensemble of trees | Robust, accurate | Less interpretable |\n",
    "| Gradient Boosting | Sequential correction | High accuracy | Slow, overfits |\n",
    "| KNN | Nearest neighbors avg | Simple | Slow prediction |\n",
    "| SVR | Kernel-based | Non-linear | Hard to tune |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b24a4d",
   "metadata": {},
   "source": [
    "## 13. Metrics Justification\n",
    "\n",
    "**Regression Metrics Used:**\n",
    "- **R�**: Variance explained (target >0.9)\n",
    "- **RMSE**: Error in same units (USD)\n",
    "- **MAE**: Average absolute error\n",
    "\n",
    "R� is primary metric as it's scale-independent and intuitive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bcf70",
   "metadata": {},
   "source": [
    "## 14. Conclusion\n",
    "\n",
    "1. **Best Model**: Random Forest/Gradient Boosting\n",
    "2. **Key Features**: Lag prices, moving averages\n",
    "3. **Feature engineering** significantly improved results\n",
    "4. **Ensemble methods** outperformed linear models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Project completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
